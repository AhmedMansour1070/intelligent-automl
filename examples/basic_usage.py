#!/usr/bin/env python
"""
Basic usage example of Intelligent AutoML Framework

This example shows the simplest way to use the intelligent AutoML framework
with a sample dataset.
"""

import pandas as pd
import numpy as np
from intelligent_automl import create_intelligent_pipeline

def create_sample_data():
    """Create a sample dataset for demonstration."""
    np.random.seed(42)
    
    data = {
        'age': np.random.normal(35, 10, 1000),
        'income': np.random.exponential(50000, 1000),
        'city': np.random.choice(['NYC', 'LA', 'Chicago', 'Houston'], 1000),
        'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], 1000),
        'signup_date': pd.date_range('2020-01-01', periods=1000, freq='D'),
        'target': np.random.choice([0, 1], 1000, p=[0.7, 0.3])
    }
    
    df = pd.DataFrame(data)
    
    # Add some missing values
    missing_indices = np.random.choice(1000, size=100, replace=False)
    df.loc[missing_indices[:50], 'age'] = np.nan
    df.loc[missing_indices[50:], 'income'] = np.nan
    
    return df

def main():
    """Main demonstration function."""
    print("ğŸš€ Intelligent AutoML Framework - Basic Example")
    print("=" * 60)
    
    # Create sample data
    print("ğŸ“Š Creating sample dataset...")
    df = create_sample_data()
    print(f"âœ… Dataset created: {df.shape[0]} rows Ã— {df.shape[1]} columns")
    print(f"ğŸ“‹ Columns: {list(df.columns)}")
    print(f"âŒ Missing values: {df.isnull().sum().sum()}")
    
    # Create intelligent pipeline
    print("\nğŸ§  Creating intelligent pipeline...")
    pipeline = create_intelligent_pipeline(df, target_column='target')
    
    # Process data
    print("\nâš™ï¸ Processing data...")
    features = df.drop('target', axis=1)
    target = df['target']
    
    processed_features = pipeline.fit_transform(features)
    
    # Results
    print(f"\nâœ… Processing complete!")
    print(f"ğŸ“ˆ Features: {features.shape[1]} â†’ {processed_features.shape[1]}")
    print(f"ğŸ¯ Missing values after processing: {processed_features.isnull().sum().sum()}")
    print(f"ğŸ’¾ Memory usage: {processed_features.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    
    # Show sample of processed data
    print(f"\nğŸ“‹ Sample of processed data:")
    print(processed_features.head())
    
    # Performance summary
    improvement = processed_features.shape[1] / features.shape[1]
    print(f"\nğŸ‰ RESULTS SUMMARY:")
    print(f"  âœ… Zero missing values achieved")
    print(f"  ğŸ“ˆ Feature engineering: {improvement:.1f}x expansion")
    print(f"  ğŸ§  Intelligent preprocessing applied automatically")
    print(f"  ğŸš€ Ready for machine learning!")

if __name__ == "__main__":
    main()