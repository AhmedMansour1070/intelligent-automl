#!/usr/bin/env python3
"""
quick_test.py - Quick test script for Intelligent AutoML Framework

This script provides a comprehensive test of the framework to ensure
everything is working correctly after installation.
"""

import sys
import time
import warnings
warnings.filterwarnings('ignore')

def test_imports():
    """Test that all components can be imported."""
    print("üß™ Testing imports...")
    
    try:
        # Test main imports
        import intelligent_automl
        print(f"  ‚úÖ Main package: v{intelligent_automl.__version__}")
        
        from intelligent_automl import IntelligentAutoMLFramework
        print("  ‚úÖ Main framework class")
        
        from intelligent_automl import create_intelligent_pipeline
        print("  ‚úÖ Pipeline creation function")
        
        from intelligent_automl.intelligence import IntelligentPipelineSelector
        print("  ‚úÖ Intelligence module")
        
        from intelligent_automl.data import DataPipeline
        print("  ‚úÖ Data processing components")
        
        # Test individual components that should exist
        from intelligent_automl.data import MissingValueHandler, FeatureScaler, CategoricalEncoder
        print("  ‚úÖ Data preprocessors")
        
        # Test models module (might not be fully implemented)
        try:
            from intelligent_automl.models import AutoModelTrainer
            print("  ‚úÖ Model training components")
        except ImportError:
            print("  ‚ö†Ô∏è Model training components (not fully implemented yet)")
        
        # Test utils module
        try:
            from intelligent_automl.utils import validate_dataset, DataProfiler
            print("  ‚úÖ Utility components")
        except ImportError:
            print("  ‚ö†Ô∏è Utility components (some may not be implemented yet)")
        
        return True
    except ImportError as e:
        print(f"  ‚ùå Import failed: {e}")
        return False

def test_basic_functionality():
    """Test basic functionality with sample data."""
    print("\nüß™ Testing basic functionality...")
    
    try:
        import pandas as pd
        import numpy as np
        from intelligent_automl import create_intelligent_pipeline
        
        # Create sample data
        np.random.seed(42)
        data = {
            'numeric1': np.random.normal(0, 1, 100),
            'numeric2': np.random.exponential(1, 100),
            'category': np.random.choice(['A', 'B', 'C'], 100),
            'target': np.random.choice([0, 1], 100)
        }
        df = pd.DataFrame(data)
        
        # Add some missing values
        df.loc[::10, 'numeric1'] = np.nan
        df.loc[::15, 'category'] = np.nan
        
        print(f"  üìä Created test data: {df.shape}")
        
        # Test pipeline creation
        pipeline = create_intelligent_pipeline(df, target_column='target')
        print(f"  ‚úÖ Pipeline created with {len(pipeline)} steps")
        
        # Test preprocessing
        features = df.drop('target', axis=1)
        processed = pipeline.fit_transform(features)
        print(f"  ‚úÖ Preprocessing: {features.shape} ‚Üí {processed.shape}")
        
        # Verify data quality
        missing_after = processed.isnull().sum().sum()
        print(f"  ‚úÖ Missing values: {missing_after} (should be 0)")
        
        return True
    except Exception as e:
        print(f"  ‚ùå Basic functionality test failed: {e}")
        return False

def test_complete_framework():
    """Test the complete AutoML framework."""
    print("\nüß™ Testing complete AutoML framework...")
    
    try:
        import pandas as pd
        import numpy as np
        from intelligent_automl import IntelligentAutoMLFramework
        
        # Create sample data
        np.random.seed(42)
        data = {
            'age': np.random.normal(35, 10, 200),
            'income': np.random.exponential(50000, 200),
            'city': np.random.choice(['NYC', 'LA', 'Chicago'], 200),
            'target': np.random.choice([0, 1], 200)
        }
        df = pd.DataFrame(data)
        
        # Save to temporary file
        df.to_csv('test_data.csv', index=False)
        print("  üìä Created test dataset: 200 rows √ó 4 columns")
        
        # Test complete framework
        framework = IntelligentAutoMLFramework(verbose=False)
        print("  ‚úÖ Framework initialized")
        
        # Run quick pipeline (with time limit for testing)
        start_time = time.time()
        results = framework.run_complete_pipeline(
            'test_data.csv',
            'target',
            models_to_try=['random_forest'],  # Just one model for speed
            time_limit_minutes=1
        )
        end_time = time.time()
        
        print(f"  ‚úÖ Complete pipeline finished in {end_time - start_time:.1f}s")
        print(f"  üèÜ Best model: {results['results']['model_training']['best_model']}")
        print(f"  üìä Best score: {results['results']['model_training']['best_score']:.4f}")
        
        # Cleanup
        import os
        if os.path.exists('test_data.csv'):
            os.remove('test_data.csv')
        
        return True
    except Exception as e:
        print(f"  ‚ùå Complete framework test failed: {e}")
        print(f"      This is expected if AutoModelTrainer is not fully implemented yet")
        return False

def test_performance():
    """Test performance with larger dataset."""
    print("\nüß™ Testing performance...")
    
    try:
        import pandas as pd
        import numpy as np
        from intelligent_automl import create_intelligent_pipeline
        
        # Create larger dataset
        np.random.seed(42)
        n_samples = 1000
        data = {
            'num1': np.random.normal(0, 1, n_samples),
            'num2': np.random.exponential(1, n_samples),
            'num3': np.random.gamma(2, 2, n_samples),
            'cat1': np.random.choice(['A', 'B', 'C', 'D'], n_samples),
            'cat2': np.random.choice(['X', 'Y', 'Z'], n_samples),
            'target': np.random.choice([0, 1], n_samples)
        }
        df = pd.DataFrame(data)
        
        # Add missing values
        missing_idx = np.random.choice(n_samples, size=100, replace=False)
        df.loc[missing_idx[:50], 'num1'] = np.nan
        df.loc[missing_idx[50:], 'cat1'] = np.nan
        
        print(f"  üìä Created performance test data: {df.shape}")
        
        # Test processing speed
        start_time = time.time()
        pipeline = create_intelligent_pipeline(df, target_column='target')
        features = df.drop('target', axis=1)
        processed = pipeline.fit_transform(features)
        end_time = time.time()
        
        processing_time = end_time - start_time
        throughput = len(df) / processing_time if processing_time > 0 else float('inf')
        
        print(f"  ‚ö° Processing time: {processing_time:.3f}s")
        print(f"  üöÄ Throughput: {throughput:.0f} rows/second")
        print(f"  üìà Feature expansion: {features.shape[1]} ‚Üí {processed.shape[1]}")
        print(f"  üéØ Data quality: {processed.isnull().sum().sum()} missing values")
        
        return True
    except Exception as e:
        print(f"  ‚ùå Performance test failed: {e}")
        return False

def test_data_formats():
    """Test support for different data formats."""
    print("\nüß™ Testing data format support...")
    
    try:
        import pandas as pd
        import numpy as np
        from intelligent_automl.data import load_data
        
        # Create test data
        np.random.seed(42)
        data = {
            'feature1': np.random.normal(0, 1, 50),
            'feature2': np.random.choice(['A', 'B'], 50),
            'target': np.random.choice([0, 1], 50)
        }
        df = pd.DataFrame(data)
        
        # Test CSV format
        df.to_csv('test_formats.csv', index=False)
        loaded_csv = load_data('test_formats.csv')
        print(f"  ‚úÖ CSV format: {loaded_csv.shape}")
        
        # Test Excel format (if openpyxl is available)
        try:
            df.to_excel('test_formats.xlsx', index=False)
            loaded_excel = load_data('test_formats.xlsx')
            print(f"  ‚úÖ Excel format: {loaded_excel.shape}")
        except ImportError:
            print("  ‚ö†Ô∏è Excel format: openpyxl not available (optional)")
        except Exception:
            print("  ‚ö†Ô∏è Excel format: not supported in this environment")
        
        # Test JSON format
        df.to_json('test_formats.json', orient='records')
        loaded_json = load_data('test_formats.json')
        print(f"  ‚úÖ JSON format: {loaded_json.shape}")
        
        # Cleanup
        import os
        for file in ['test_formats.csv', 'test_formats.xlsx', 'test_formats.json']:
            if os.path.exists(file):
                os.remove(file)
        
        return True
    except Exception as e:
        print(f"  ‚ùå Data format test failed: {e}")
        return False

def check_dependencies():
    """Check that all required dependencies are available."""
    print("\nüß™ Checking dependencies...")
    
    required_packages = [
        'pandas', 'numpy', 'sklearn', 
        'matplotlib', 'seaborn', 'joblib', 'tqdm'
    ]
    
    optional_packages = [
        'xgboost', 'lightgbm', 'catboost'
    ]
    
    all_good = True
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"  ‚úÖ {package}")
        except ImportError:
            print(f"  ‚ùå {package} (required)")
            all_good = False
    
    print("  üì¶ Optional packages:")
    for package in optional_packages:
        try:
            __import__(package)
            print(f"  ‚úÖ {package} (optional)")
        except ImportError:
            print(f"  ‚ö†Ô∏è {package} (optional - install for advanced features)")
    
    return all_good

def test_real_data():
    """Test with real data if available."""
    print("\nüß™ Testing with real data (if available)...")
    
    try:
        import pandas as pd
        import os
        from intelligent_automl import create_intelligent_pipeline
        
        # Check if test.csv or test_fixed.csv exists
        data_files = ['test.csv', 'test_fixed.csv']
        test_file = None
        
        for file in data_files:
            if os.path.exists(file):
                test_file = file
                break
        
        if test_file:
            print(f"  üìä Found real data file: {test_file}")
            
            # Load a sample (first 1000 rows for testing)
            df = pd.read_csv(test_file).head(1000)
            print(f"  üìà Loaded sample: {df.shape}")
            
            # Try to detect target column
            target_col = None
            potential_targets = ['target', 'trip_duration', 'label', 'y']
            
            for col in potential_targets:
                if col in df.columns:
                    target_col = col
                    break
            
            if target_col:
                print(f"  üéØ Target column: {target_col}")
                
                # Test pipeline creation
                pipeline = create_intelligent_pipeline(df, target_column=target_col)
                print(f"  ‚úÖ Real data pipeline created with {len(pipeline)} steps")
                
                # Test preprocessing on sample
                features = df.drop(target_col, axis=1)
                processed = pipeline.fit_transform(features)
                print(f"  ‚úÖ Real data processing: {features.shape} ‚Üí {processed.shape}")
                
                return True
            else:
                print("  ‚ö†Ô∏è No recognizable target column found")
                return True
        else:
            print("  ‚ö†Ô∏è No real data files found (test.csv, test_fixed.csv)")
            return True
            
    except Exception as e:
        print(f"  ‚ùå Real data test failed: {e}")
        return False

def test_intelligence_features():
    """Test specific intelligence features."""
    print("\nüß™ Testing intelligence features...")
    
    try:
        import pandas as pd
        import numpy as np
        from intelligent_automl.intelligence import IntelligentPipelineSelector
        
        # Create complex test data
        np.random.seed(42)
        data = {
            'numeric_clean': np.random.normal(0, 1, 100),
            'numeric_skewed': np.random.exponential(1, 100),
            'numeric_with_outliers': np.concatenate([np.random.normal(0, 1, 95), [10, -10, 15, -15, 20]]),
            'category_low_card': np.random.choice(['A', 'B', 'C'], 100),
            'category_high_card': [f'item_{i}' for i in np.random.randint(0, 80, 100)],
            'datetime_feature': pd.date_range('2020-01-01', periods=100, freq='D'),
            'target': np.random.choice([0, 1], 100)
        }
        df = pd.DataFrame(data)
        
        # Add missing values in different patterns
        df.loc[::10, 'numeric_clean'] = np.nan
        df.loc[::15, 'category_low_card'] = np.nan
        
        print(f"  üìä Created complex test data: {df.shape}")
        
        # Test intelligent analysis
        selector = IntelligentPipelineSelector(target_column='target')
        characteristics = selector.analyze_data(df)
        
        print(f"  üß† Data analysis complete:")
        print(f"    ‚Ä¢ Numeric features: {len(characteristics.numeric_features)}")
        print(f"    ‚Ä¢ Categorical features: {len(characteristics.categorical_features)}")
        print(f"    ‚Ä¢ DateTime features: {len(characteristics.datetime_features)}")
        print(f"    ‚Ä¢ Missing pattern: {characteristics.missing_pattern}")
        print(f"    ‚Ä¢ Target type: {characteristics.target_type}")
        
        # Test intelligent recommendations
        recommendations = selector.generate_recommendations()
        print(f"  üí° Generated {len(recommendations)} recommendations")
        
        # Test pipeline building
        pipeline = selector.build_intelligent_pipeline()
        print(f"  üîß Built intelligent pipeline with {len(pipeline)} steps")
        
        # Test explanation
        explanation = selector.explain_recommendations()
        print(f"  üìù Generated explanation ({len(explanation)} characters)")
        
        return True
        
    except Exception as e:
        print(f"  ‚ùå Intelligence features test failed: {e}")
        return False

def main():
    """Run all tests."""
    print("üß† Intelligent AutoML Framework - Quick Test")
    print("=" * 60)
    print("Testing installation and basic functionality...\n")
    
    tests = [
        ("Import Test", test_imports),
        ("Dependency Check", check_dependencies),
        ("Basic Functionality", test_basic_functionality),
        ("Intelligence Features", test_intelligence_features),
        ("Performance Test", test_performance),
        ("Data Format Support", test_data_formats),
        ("Real Data Test", test_real_data),
        ("Complete Framework", test_complete_framework),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"Running {test_name}...")
        try:
            if test_func():
                passed += 1
                print(f"‚úÖ {test_name} PASSED\n")
            else:
                print(f"‚ùå {test_name} FAILED\n")
        except Exception as e:
            print(f"‚ùå {test_name} FAILED: {e}\n")
    
    # Results summary
    print("=" * 60)
    print("üéØ TEST RESULTS SUMMARY")
    print("=" * 60)
    print(f"Passed: {passed}/{total} tests")
    
    if passed == total:
        print("üéâ ALL TESTS PASSED!")
        print("\n‚úÖ Your Intelligent AutoML installation is working perfectly!")
        print("\nüöÄ Next Steps:")
        print("  1. Try: python examples/basic_usage.py")
        print("  2. Explore: python examples/advanced_pipeline.py")
        print("  3. Use your data: python examples/how_to_use_simple.py")
        print("  4. Read: README.md for detailed documentation")
        print("\nüß† Happy AutoML-ing!")
        return 0
    elif passed >= total - 2:
        print("üéâ ALMOST ALL TESTS PASSED!")
        print("\n‚úÖ Your Intelligent AutoML core functionality is working!")
        print("\nüöÄ You can proceed with:")
        print("  1. python examples/basic_usage.py")
        print("  2. python examples/how_to_use_simple.py")
        print("  3. python examples/comprehensive_demo.py")
        print("\nüí° The failing tests are likely advanced features that are optional.")
        return 0
    elif passed >= total // 2:
        print("‚ö†Ô∏è Some core functionality working!")
        print("\nüîß Next Steps:")
        print("  1. Install missing dependencies if any")
        print("  2. Try the basic examples that should work")
        print("  3. Check the failed tests for specific issues")
        return 0
    else:
        print("‚ö†Ô∏è Multiple tests failed.")
        print("\nüîß Troubleshooting:")
        print("  1. Install scikit-learn: pip install scikit-learn")
        print("  2. Install all dependencies: pip install -r requirements.txt")
        print("  3. Verify Python version is 3.8+: python --version")
        print("  4. Try reinstalling: pip install -e .")
        print("  5. Check if you're in the right directory")
        print("  6. Ensure the missing __init__.py files are created")
        return 1

if __name__ == "__main__":
    sys.exit(main())
